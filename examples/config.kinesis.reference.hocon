# Copyright (c) 2014-2021 Snowplow Analytics Ltd. All rights reserved.
#
# This program is licensed to you under the Apache License Version 2.0, and
# you may not use this file except in compliance with the Apache License
# Version 2.0.  You may obtain a copy of the Apache License Version 2.0 at
# http://www.apache.org/licenses/LICENSE-2.0.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the Apache License Version 2.0 is distributed on an "AS
# IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.  See the Apache License Version 2.0 for the specific language
# governing permissions and limitations there under.

# This file (config.kinesis.reference.hocon) contains a template with
# configuration options for the Elasticsearch Loader.

"input": {
  # Sources currently supported are:
  # "kinesis" for reading records from a Kinesis stream
  # "stdin" for reading unencoded tab-separated events from stdin
  # If set to "stdin", JSON documents will not be sent to Elasticsearch
  # but will be written to stdout.
  # "nsq" for reading unencoded tab-separated events from NSQ
  "type": "kinesis"

  # Stream name for incoming data
  "streamName": "test-kinesis-stream"

  # Config for Kinesis
  # "LATEST": most recent data.
  # "TRIM_HORIZON": oldest available data.
  # "AT_TIMESTAMP": Start from the record at or after the specified timestamp
  # Note: This only affects the first run of this application on a stream.
  "initialPosition": "AT_TIMESTAMP"

  # Need to be specified when initial-position is "AT_TIMESTAMP".
  # Timestamp format need to be in "yyyy-MM-ddTHH:mm:ssZ".
  # Ex: "2017-05-17T10:00:00Z"
  # Note: Time need to specified in UTC.
  "initialTimestamp": "2020-07-17T10:00:00Z"

  # Optional maximum number of records to get from Kinesis per call to GetRecords
  # Default value 10000
  "maxRecords": 9999

  # Region where the Kinesis stream is located
  "region": "eu-central-1"

  # Optional endpoint url configuration to override aws kinesis endpoints,
  # this can be used to specify local endpoints when using localstack
  "customEndpoint": "127.0.0.1"

  # Optional endpoint url configuration to override aws dyanomdb endpoints for Kinesis checkpoints lease table,
  # this can be used to specify local endpoints when using Localstack
  "dynamodbCustomEndpoint": "http://localhost:4569"

  # "appName" is used for a DynamoDB table to maintain stream state.
  # Default value "snowplow-elasticsearch-loader"
  "appName": "test-app-name"

  # Events are accumulated in a buffer before being sent to Elasticsearch.
  # These values are optional.
  # The buffer is emptied whenever:
  # - the combined size of the stored records exceeds byteLimit or
  # - the number of stored records exceeds recordLimit or
  # - the time in milliseconds since it was last emptied exceeds timeLimit
  "buffer": {
    "byteLimit": 999999 # Default value 1000000
    "recordLimit": 499  # Default value 500
    "timeLimit": 499    # Default value 500
  }
}

"output": {
  "good": {
    # Good sinks currently supported are:
    # "elasticsearch" for writing good records to Elasticsearch
    # "stdout" for writing good records to stdout
    "type": "elasticsearch"

    # Events are indexed using an Elasticsearch Client
    # - endpoint: the cluster endpoint
    # - port: the port the cluster can be accessed on
    #   - for http this is usually 9200
    #   - for transport this is usually 9300
    # - username (optional, remove if not active): http basic auth username
    # - password (optional, remove if not active): http basic auth password
    # - shardDateFormat (optional, remove if not needed): formatting used for sharding good stream, i.e. _yyyy-MM-dd
    # - shardDateField (optional, if not specified derived_tstamp is used): timestamp field for sharding good stream
    # - maxTimeout (optional, default value 10000): the maximum attempt time before a client restart
    # - maxRetries (optional, default value 6): the maximum number of request attempts before giving up
    # - ssl: if using the http client, whether to use ssl or not
    "client": {
      "endpoint": "localhost"
      "port": 9200
      "username": "es-user"
      "password": "es-pass"
      "shardDateFormat": "_yyyy-MM-dd"
      "shardDateField": "derived_tstamp"
      "maxTimeout": 9999
      "maxRetries": 5
      "ssl": true
    }

    # When using the AWS ES service
    # - signing: if using the http client and the AWS ES service you can sign your requests
    #    http://docs.aws.amazon.com/general/latest/gr/signing_aws_api_requests.html
    # - region where the AWS ES service is located
    "aws": {
      "signing": true
      "region": "eu-central-1"
    }

    "cluster": {
      # The Elasticsearch index name
      "index": "good"
      # The Elasticsearch index type.
      # Index types are deprecated in ES >=7.x
      # Therefore, it shouldn't be set with ES >=7.x
      "documentType": "good-doc"
    }

    # Bulk request to Elasticsearch will be splitted to
    # chunks according given limits.
    # These values are optional.
    "chunk": {
      "byteLimit": 999999 # Default value is 1000000
      "recordLimit": 499  # Default value is 500
    }
  }
  "bad" {
    # Bad sinks currently supported are:
    # "kinesis" for writing bad records to Kinesis
    # "stderr" for writing bad records to stderr
    # "nsq" for writing bad records to NSQ
    # "none" for ignoring bad records
    "type": "kinesis"

    # Stream name for events which are rejected by Elasticsearch
    "streamName": "test-kinesis-bad-stream"

    # Region where the Kinesis stream is located
    "region": "eu-central-1"

    # Optional endpoint url configuration to override aws kinesis endpoints,
    # this can be used to specify local endpoints when using localstack
    "customEndpoint": "127.0.0.1:7846"
  }
}

# "good" for a stream of successfully enriched events
# "bad" for a stream of bad events
# "plain-json" for writing plain json
"purpose": "good"

# Optional section for tracking endpoints
"monitoring": {
  "snowplow": {
    "collector": "localhost:14322"
    "appId": "test-app-id"
  }

  "metrics": {
    # Optional, cloudwatch metrics are enabled by default.
    "cloudWatch": false
  }
}
